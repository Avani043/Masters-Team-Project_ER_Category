{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIsGvF1ynscA","outputId":"9e117b2d-7cdc-464b-d0ec-551f876873ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","/content/drive/My Drive/Team Project\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive/')\n","    %cd 'drive/My Drive/Team Project'\n","except ImportError as e:\n","    pass"]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"d0F8aRisoOqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel(\"Journal_500Dataset.xlsx\")"],"metadata":{"id":"BfoMI7F_oUKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9rwuWkyohC_","outputId":"02bfbeaa-9c04-4a16-effa-39613dc1b7b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 500 entries, 0 to 499\n","Data columns (total 3 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   text_cleaned  500 non-null    object\n"," 1   er_strat      480 non-null    object\n"," 2   adaptive      429 non-null    object\n","dtypes: object(3)\n","memory usage: 11.8+ KB\n"]}]},{"cell_type":"code","source":["df['er_strat'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":837},"id":"g-OHKkrwphW9","outputId":"70d717f2-e0cb-46ed-e346-365bded09763"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["er_strat\n","Attentional Deployment                                                                   142\n","Cognitive Change                                                                         113\n","Response Modulation                                                                       63\n","none                                                                                      58\n","Situation Selection                                                                       20\n","Situation Modification                                                                    15\n","Response Modulation, Cognitive Change                                                     14\n","Situation Selection, Cognitive Change                                                     11\n","Attentional Deployment, Cognitive Change                                                   7\n","Situation Modification, Attentional Deployment                                             7\n","Attentional Deployment, Response Modulation                                                6\n","Attentional Deployment, Situation Selection                                                5\n","Situation Modification, Response Modulation                                                4\n","Situation Modification, Cognitive Change                                                   3\n","Response Modulation, Situation Selection                                                   2\n","Cognitive Change, Response Modulation, Situation Selection                                 2\n","Response Modulation, Cognitive Change, Attentional Deployment, Situation Modification      2\n","Response Modulation, Cognitive Change, Situation Modification                              1\n","Cognitive Change, Situation Selection, Situation Modification, Attentional Deployment      1\n","Situation Selection, Situation Modification                                                1\n","Cognitive Change, Attentional Deployment, Situation Modification                           1\n","Situation Selection, Cognitive Change, Attentional Deployment                              1\n","Attentional Deployment, Cognitive Change, Response Modulation                              1\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>er_strat</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Attentional Deployment</th>\n","      <td>142</td>\n","    </tr>\n","    <tr>\n","      <th>Cognitive Change</th>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>Response Modulation</th>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>none</th>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Selection</th>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Modification</th>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>Response Modulation, Cognitive Change</th>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Selection, Cognitive Change</th>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>Attentional Deployment, Cognitive Change</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Modification, Attentional Deployment</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>Attentional Deployment, Response Modulation</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>Attentional Deployment, Situation Selection</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Modification, Response Modulation</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Modification, Cognitive Change</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Response Modulation, Situation Selection</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Cognitive Change, Response Modulation, Situation Selection</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Response Modulation, Cognitive Change, Attentional Deployment, Situation Modification</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Response Modulation, Cognitive Change, Situation Modification</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Cognitive Change, Situation Selection, Situation Modification, Attentional Deployment</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Selection, Situation Modification</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Cognitive Change, Attentional Deployment, Situation Modification</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Situation Selection, Cognitive Change, Attentional Deployment</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Attentional Deployment, Cognitive Change, Response Modulation</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["**Neural Network Approach**"],"metadata":{"id":"YreiMMK4zYpE"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.utils.class_weight import compute_sample_weight\n","from sklearn.metrics import classification_report  # Import classification_report\n","import joblib\n","import traceback\n","\n","# TF-IDF Vectorization\n","def tfidf_vectorizer(X_train, X_test):\n","    try:\n","        vectorizer = TfidfVectorizer(max_features=4000, ngram_range=(1, 2))\n","        X_train = vectorizer.fit_transform(X_train)\n","        X_test = vectorizer.transform(X_test)\n","        joblib.dump(vectorizer, \"tfidf_vectorizer.sav\")\n","        return X_train.toarray(), X_test.toarray()  # Convert sparse matrix to array\n","    except Exception as e:\n","        print(f\"Error in TF-IDF Vectorization: {e}\")\n","        traceback.print_exc()\n","\n","# Build Neural Network Model\n","def build_model(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(512, activation='relu', input_dim=input_dim),\n","        Dropout(0.3),\n","        Dense(256, activation='relu'),\n","        Dropout(0.3),\n","        Dense(output_dim, activation='sigmoid')  # Sigmoid for multi-label classification\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss='binary_crossentropy',  # Binary crossentropy for multi-label\n","                  metrics=['accuracy'])\n","    return model\n","\n","# Main Script\n","try:\n","    # Load Dataset\n","    file_path = \"Dataset500.xlsx\"  # Update file path\n","    df = pd.read_excel(file_path)\n","    df = df[df['er_strat'].notna()]  # Drop rows with missing labels\n","    df[\"labels\"] = df[\"er_strat\"].apply(lambda x: x.split(\", \"))  # Convert to list\n","\n","    # Encode Labels using MultiLabelBinarizer\n","    mlb = MultiLabelBinarizer()\n","    y = mlb.fit_transform(df[\"labels\"])\n","    X = df[\"text_cleaned\"]\n","\n","    # Train-Test Split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.3, random_state=42\n","    )\n","\n","    # Apply TF-IDF\n","    X_train, X_test = tfidf_vectorizer(X_train, X_test)\n","\n","    # Compute Sample Weights for Imbalance Handling\n","    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n","\n","    # Build & Train Model\n","    model = build_model(input_dim=X_train.shape[1], output_dim=y_train.shape[1])\n","\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","\n","    model.fit(X_train, y_train,\n","              validation_data=(X_test, y_test),\n","              epochs=50,\n","              batch_size=32,\n","              sample_weight=sample_weights,  # Adjust weights for imbalance\n","              callbacks=[early_stopping],\n","              verbose=1)\n","\n","    # Save the model\n","    model.save(\"multi_label_nn_model.h5\")\n","\n","    # Evaluate Model\n","    loss, accuracy = model.evaluate(X_test, y_test)\n","    print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","    # Make Predictions\n","    y_pred = model.predict(X_test)\n","    y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n","\n","    # Save classification report\n","    report = classification_report(y_test, y_pred_binary, target_names=mlb.classes_, zero_division=0, output_dict=True)\n","    pd.DataFrame(report).transpose().to_csv(\"NN_classification_report.csv\")\n","\n","except Exception as e:\n","    print(f\"Error in main script: {e}\")\n","    traceback.print_exc()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXY7o6CeuL6V","outputId":"ff973a93-a539-4a91-8b75-6ec4baa760ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2900 - loss: 0.2492 - val_accuracy: 0.3403 - val_loss: 0.5944\n","Epoch 2/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3089 - loss: 0.2270 - val_accuracy: 0.3403 - val_loss: 0.5128\n","Epoch 3/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3512 - loss: 0.2144 - val_accuracy: 0.3403 - val_loss: 0.5091\n","Epoch 4/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3421 - loss: 0.1890 - val_accuracy: 0.2986 - val_loss: 0.5069\n","Epoch 5/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4966 - loss: 0.1649 - val_accuracy: 0.3264 - val_loss: 0.4900\n","Epoch 6/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7745 - loss: 0.1466 - val_accuracy: 0.3681 - val_loss: 0.4758\n","Epoch 7/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8879 - loss: 0.1095 - val_accuracy: 0.3958 - val_loss: 0.4734\n","Epoch 8/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9205 - loss: 0.0702 - val_accuracy: 0.4097 - val_loss: 0.4704\n","Epoch 9/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9162 - loss: 0.0402 - val_accuracy: 0.4167 - val_loss: 0.4795\n","Epoch 10/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9319 - loss: 0.0284 - val_accuracy: 0.4306 - val_loss: 0.5034\n","Epoch 11/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9065 - loss: 0.0180 - val_accuracy: 0.4236 - val_loss: 0.5351\n","Epoch 12/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9020 - loss: 0.0103 - val_accuracy: 0.4444 - val_loss: 0.5524\n","Epoch 13/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9104 - loss: 0.0090 - val_accuracy: 0.4444 - val_loss: 0.5716\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4473 - loss: 0.4504\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7af8d8a96840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.4097\n","\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7af8d8a96840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"]}]},{"cell_type":"markdown","source":["**CNN + BiLSTM Approach**"],"metadata":{"id":"XMo621ALzhjZ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Bidirectional, Flatten\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report\n","\n","# Load Dataset\n","file_path = \"Dataset500.xlsx\"  # Update file path\n","df = pd.read_excel(file_path)\n","df = df[df['er_strat'].notna()]  # Drop missing labels\n","df[\"labels\"] = df[\"er_strat\"].apply(lambda x: x.split(\", \"))  # Convert labels to list\n","\n","# Encode Labels\n","mlb = MultiLabelBinarizer()\n","y = mlb.fit_transform(df[\"labels\"])\n","X = df[\"text_cleaned\"]\n","\n","# Tokenization & Padding\n","tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(X)\n","X_seq = tokenizer.texts_to_sequences(X)\n","X_padded = pad_sequences(X_seq, maxlen=200, padding=\"post\", truncating=\"post\")\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.3, random_state=42)\n","\n","# Build CNN + BiLSTM Model\n","model = Sequential([\n","    Embedding(input_dim=5000, output_dim=128, input_length=200),\n","    Conv1D(filters=64, kernel_size=5, activation=\"relu\"),\n","    MaxPooling1D(pool_size=2),\n","    Bidirectional(LSTM(128, return_sequences=True)),\n","    Flatten(),\n","    Dense(128, activation=\"relu\"),\n","    Dropout(0.5),\n","    Dense(y.shape[1], activation=\"sigmoid\")  # Multi-label classification\n","])\n","\n","model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Train Model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)\n","\n","# Save Model\n","model.save(\"cnn_bilstm_model.h5\")\n","\n","# Evaluate Model\n","y_pred = (model.predict(X_test) > 0.5).astype(int)\n","print(classification_report(y_test, y_pred, target_names=mlb.classes_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhCDDtxmyPJQ","outputId":"b4c5dd2e-885a-4c5c-e1c1-cd7174a9c10d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.2177 - loss: 0.5786 - val_accuracy: 0.3542 - val_loss: 0.4638\n","Epoch 2/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 329ms/step - accuracy: 0.3323 - loss: 0.4468 - val_accuracy: 0.4028 - val_loss: 0.4467\n","Epoch 3/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 464ms/step - accuracy: 0.3635 - loss: 0.4438 - val_accuracy: 0.4306 - val_loss: 0.4394\n","Epoch 4/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 299ms/step - accuracy: 0.4270 - loss: 0.4268 - val_accuracy: 0.4306 - val_loss: 0.4296\n","Epoch 5/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - accuracy: 0.5215 - loss: 0.3944 - val_accuracy: 0.4306 - val_loss: 0.4336\n","Epoch 6/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 403ms/step - accuracy: 0.5531 - loss: 0.3648 - val_accuracy: 0.4514 - val_loss: 0.4424\n","Epoch 7/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 326ms/step - accuracy: 0.6457 - loss: 0.3052 - val_accuracy: 0.4444 - val_loss: 0.4573\n","Epoch 8/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 414ms/step - accuracy: 0.7061 - loss: 0.2617 - val_accuracy: 0.5000 - val_loss: 0.4790\n","Epoch 9/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - accuracy: 0.7804 - loss: 0.2344 - val_accuracy: 0.4792 - val_loss: 0.4865\n","Epoch 10/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 300ms/step - accuracy: 0.8157 - loss: 0.1739 - val_accuracy: 0.3889 - val_loss: 0.5842\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n","                        precision    recall  f1-score   support\n","\n","Attentional Deployment       0.44      0.27      0.34        51\n","      Cognitive Change       0.60      0.48      0.53        56\n","   Response Modulation       0.28      0.33      0.31        27\n","Situation Modification       0.00      0.00      0.00        13\n","   Situation Selection       0.00      0.00      0.00        14\n","                  none       1.00      0.42      0.59        19\n","\n","             micro avg       0.49      0.32      0.39       180\n","             macro avg       0.39      0.25      0.29       180\n","          weighted avg       0.46      0.32      0.37       180\n","           samples avg       0.38      0.34      0.34       180\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]}]}